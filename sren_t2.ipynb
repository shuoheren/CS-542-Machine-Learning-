{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9ZmxP6StAoz"
   },
   "source": [
    "# CS542 - Class Challenge - fine-grained classification of plants:\n",
    "\n",
    "Our class challenge will consists of two tasks addressing an image recognition task where our dataset contains about 1K categories of plants with only about 250,000 images.  There will be two parts to this task:\n",
    "\n",
    "1. Image classification. Imagine we have cateloged all the plants we care to identify, now we just need to create a classifier for them! Use your skills from the supervised learning sections of this course to try to address this problem.\n",
    "\n",
    "2. Semi-Supervised/Few-Shot Learning.  Unfortunately, we missed some important plants we want to classify!  We do have some images we think contain the plant, but we have only have a few labels.  Our new goal is to develop an AI model that can learn from just these labeled examples.\n",
    "\n",
    "Each student must submit a model on both tasks.  Students in the top 3 on each task will get 5% extra credit on this assignment.\n",
    "\n",
    "This notebook is associated with the second task (semi-supervised).\n",
    "\n",
    "\n",
    "# Dataset\n",
    "The dataset is downloaded on scc in the address: \"/projectnb2/cs542-bap/classChallenge/data\". You can find the python version of this notebook there as well or you could just type \"jupyter nbconvert --to script baselineModel_task2.ipynb\" and it will output \"baselineModel_task2.py\". You should be able to run \"baselineModel_task2.py\" on scc by simply typing \"python baselineModel_task2.py\"\n",
    "\n",
    "Please don't try to change or delete the dataset.\n",
    "\n",
    "# Evaluation:\n",
    "You will compete with each other over your performance on the dedicated test set. The performance measure is classification accuracy, i.e: if the true class is your top predictions. \n",
    "\n",
    "# Baseline:\n",
    "The following code is a baseline which you can use and improve to come up with your model for this task\n",
    "\n",
    "# Suggestion\n",
    "One simple suggestion would be to use a pretrained model on imagenet and finetune it on this data similar to this [link](https://keras.io/api/applications/)\n",
    "Also you should likely train more than 2 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q8oub7ntAo1"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14D2EZ17tAo1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYaBUsR-tAo3"
   },
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m893cNgztAo3"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = '/projectnb2/cs542-bap/class_challenge/'\n",
    "\n",
    "train_samps = np.loadtxt(os.path.join(data_dir, 'train_held_out_labeled.txt'), dtype='str', delimiter=\" \")\n",
    "val_samps = np.loadtxt(os.path.join(data_dir, 'val_held_out.txt'), dtype='str', delimiter=\" \")\n",
    "\n",
    "train_len = len(train_samps)\n",
    "\n",
    "val_len = len(val_samps)\n",
    "\n",
    "\n",
    "samples = np.concatenate((train_samps, val_samps))\n",
    "\n",
    "unlabeled_samps = np.loadtxt(os.path.join(data_dir, 'train_held_out.txt'), dtype='str')\n",
    "unlabeled_len = len(unlabeled_samps)\n",
    "\n",
    "test_ds = tf.data.TextLineDataset(os.path.join(data_dir, 'test_held_out.txt'))\n",
    "\n",
    "with open(os.path.join(data_dir, 'classes_held_out.txt'), 'r') as f:\n",
    "    class_names = [c.strip() for c in f.readlines()]\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m6getXwtAo3"
   },
   "source": [
    "## Write a short function that converts a file path to an (img, label) pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrIrN5iItAo3"
   },
   "outputs": [],
   "source": [
    "def decode_img(img, test=False, crop_size=224):\n",
    "    img = tf.io.read_file(img)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "    return tf.image.resize(img, [crop_size, crop_size])\n",
    "  \n",
    "def get_label(label):\n",
    "    # find teh matching label\n",
    "    one_hot = tf.where(tf.equal(label, class_names))\n",
    "    # Integer encode the label\n",
    "    return tf.reduce_min(one_hot)\n",
    "\n",
    "def process_path(path, label):\n",
    "    # should have two parts\n",
    "    # file_path = tf.strings.split(file_path)\n",
    "    # second part has the class index\n",
    "    label = get_label(label)\n",
    "   # load the raw data from the file\n",
    "    img = decode_img(tf.strings.join([data_dir, 'images/', path, '.jpg']))\n",
    "    return img, label\n",
    "\n",
    "def process_path_test(file_path):\n",
    "    # load the raw data from the file\n",
    "    img = decode_img(tf.strings.join([data_dir, 'images/', file_path, '.jpg']))\n",
    "    return img, file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epSS5nlYtAo3"
   },
   "source": [
    "# Finish setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIrk9SuYtAo3"
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "test_ds = test_ds.map(process_path_test, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def shuffle_train_val(train_perc = 0.2):\n",
    "    # define the train length\n",
    "    train_len = int(train_perc*len(samples))\n",
    "    \n",
    "    # idexing train set and val set by random choice\n",
    "    train_idx = np.random.choice(range(len(samples)), train_len, replace=True)\n",
    "    val_idx = [idx for idx in range(len(samples)) if idx not in train_idx]\n",
    "    \n",
    "    # get train_ds and val_ds based on indexes\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((samples[train_idx, 0], samples[train_idx, 1]))\n",
    "    train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    train_ds = configure_for_performance(train_ds)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((samples[val_idx, 0], samples[val_idx, 1]))\n",
    "    val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    val_ds = configure_for_performance(val_ds)\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOA90IRtAo4"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c25-JMRK9aVj"
   },
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWHpzQoatAo4"
   },
   "outputs": [],
   "source": [
    "class ResNet50(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.ResNet50 = keras.applications.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "        \n",
    "        # unfreeze the last two layers\n",
    "        for layer in self.ResNet50.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # define layers\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc_1 = layers.Dense(1024)\n",
    "        self.fc_2 = layers.Dense(units=num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = keras.applications.resnet.preprocess_input(inputs)\n",
    "        x = self.ResNet50(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_1(x)\n",
    "        output = self.fc_2(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "# data augmentation\n",
    "model = Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\n",
    "        mode='horizontal'),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
    "    ResNet50()\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvq5zA2_9aVj"
   },
   "source": [
    "## EfficientB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuMPp8Vn9aVj"
   },
   "outputs": [],
   "source": [
    "class EfficientB0(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EfficientB0, self).__init__()\n",
    "        self.EfficientB0 = keras.applications.EfficientNetB0(\n",
    "             include_top=False,\n",
    "             weights='imagenet',\n",
    "             input_shape=(224, 224, 3), \n",
    "             # add stronger reguarliztions\n",
    "             drop_connect_rate=0.4\n",
    "        )\n",
    "        \n",
    "        # unfreeze top 20 layers\n",
    "        for layer in self.EfficientB0.layers[:-20]:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        # define layers\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc_1 = layers.Dense(1024)\n",
    "        self.dropout = layers.Dropout(0.3)\n",
    "        self.fc_2 = layers.Dense(units=num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.EfficientB0(inputs)\n",
    "        x = self.pool(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc_2(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "# image augmentation\n",
    "model = Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\n",
    "       mode='horizontal'),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
    "    EfficientB0()\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwRUOUKV9aVk"
   },
   "outputs": [],
   "source": [
    "def Add_labels(unlabeled_samps, model, unlabeled_batch):\n",
    "    unlabeled_ds = tf.data.Dataset.from_tensor_slices(unlabeled_samps)\n",
    "    unlabeled_ds = unlabeled_ds.map(process_path_test, num_parallel_calls=AUTOTUNE)\n",
    "    unlabeled_ds = unlabeled_ds.batch(1)\n",
    "    \n",
    "    # initialize prediction tracker\n",
    "    predictions = None\n",
    "    # initialize indexes tracker\n",
    "    inds = []\n",
    "    for image, image_name in unlabeled_ds:\n",
    "        preds = model.predict(image)\n",
    "        ind = np.argmax(preds)\n",
    "        cls = class_names[ind]\n",
    "        pred = (str(int(image_name)), cls)\n",
    "        \n",
    "        # keep tracking predictions\n",
    "        if predictions is None:\n",
    "            predictions = np.array(pred)\n",
    "        else:\n",
    "            predictions = np.vstack((predictions, pred))\n",
    "            \n",
    "        # keep tracking the indexes\n",
    "        inds.append(preds[0, ind])\n",
    "        \n",
    "    # output top n predictions, n = max_unlabeled\n",
    "    inds = np.argpartition(inds, -unlabeled_batch)[-unlabeled_batch:]\n",
    "    predictions = predictions[inds]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NysgEGg19aVk",
    "outputId": "021f5669-c2d8-4453-83ae-17863aba59e2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 2s 277ms/step - loss: 3.1210 - accuracy: 0.0355 - val_loss: 3.1184 - val_accuracy: 0.0568\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 3.0405 - accuracy: 0.0780 - val_loss: 3.0780 - val_accuracy: 0.0671\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 3.0386 - accuracy: 0.0496 - val_loss: 3.0386 - val_accuracy: 0.0775\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 2.9283 - accuracy: 0.0638 - val_loss: 3.0007 - val_accuracy: 0.1033\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.8425 - accuracy: 0.1418 - val_loss: 2.9626 - val_accuracy: 0.1153\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 2.7560 - accuracy: 0.1560 - val_loss: 2.9245 - val_accuracy: 0.1308\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 2.8424 - accuracy: 0.1064 - val_loss: 2.8882 - val_accuracy: 0.1515\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 2.7289 - accuracy: 0.1844 - val_loss: 2.8516 - val_accuracy: 0.1738\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.6512 - accuracy: 0.2411 - val_loss: 2.8152 - val_accuracy: 0.1790\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.6449 - accuracy: 0.2695 - val_loss: 2.7796 - val_accuracy: 0.1945\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 2.5545 - accuracy: 0.3050 - val_loss: 2.7442 - val_accuracy: 0.2100\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 2.5119 - accuracy: 0.3121 - val_loss: 2.7085 - val_accuracy: 0.2375\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.4500 - accuracy: 0.3475 - val_loss: 2.6742 - val_accuracy: 0.2633\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 2.3983 - accuracy: 0.3759 - val_loss: 2.6387 - val_accuracy: 0.2737\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.3792 - accuracy: 0.3830 - val_loss: 2.6054 - val_accuracy: 0.2857\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.3899 - accuracy: 0.4043 - val_loss: 2.5730 - val_accuracy: 0.3046\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.2604 - accuracy: 0.4752 - val_loss: 2.5393 - val_accuracy: 0.3201\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.3054 - accuracy: 0.3972 - val_loss: 2.5071 - val_accuracy: 0.3287\n",
      "number of unlabeled samples remained: 3788\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 2.1969 - accuracy: 0.5106 - val_loss: 2.4754 - val_accuracy: 0.3408\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 2.1951 - accuracy: 0.4965 - val_loss: 2.4452 - val_accuracy: 0.3580\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.0511 - accuracy: 0.5887 - val_loss: 2.4142 - val_accuracy: 0.3769\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.0669 - accuracy: 0.5248 - val_loss: 2.3852 - val_accuracy: 0.3890\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.0177 - accuracy: 0.5461 - val_loss: 2.3575 - val_accuracy: 0.3941\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 1.9841 - accuracy: 0.5674 - val_loss: 2.3296 - val_accuracy: 0.4200\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.9563 - accuracy: 0.6028 - val_loss: 2.3032 - val_accuracy: 0.4269\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.8900 - accuracy: 0.5957 - val_loss: 2.2766 - val_accuracy: 0.4337\n",
      "number of unlabeled samples remained: 3368\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.8554 - accuracy: 0.6525 - val_loss: 2.2491 - val_accuracy: 0.4372\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.8925 - accuracy: 0.5745 - val_loss: 2.2229 - val_accuracy: 0.4406\n",
      "number of unlabeled samples remained: 2948\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 1.8054 - accuracy: 0.6312 - val_loss: 2.1985 - val_accuracy: 0.4492\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.7589 - accuracy: 0.6667 - val_loss: 2.1738 - val_accuracy: 0.4596\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.7549 - accuracy: 0.6170 - val_loss: 2.1504 - val_accuracy: 0.4630\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.7182 - accuracy: 0.6454 - val_loss: 2.1275 - val_accuracy: 0.4699\n",
      "number of unlabeled samples remained: 2528\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 1.7454 - accuracy: 0.5816 - val_loss: 2.1062 - val_accuracy: 0.4768\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.7222 - accuracy: 0.6454 - val_loss: 2.0844 - val_accuracy: 0.4819\n",
      "number of unlabeled samples remained: 2108\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 1.6153 - accuracy: 0.6879 - val_loss: 2.0636 - val_accuracy: 0.4888\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.6259 - accuracy: 0.6879 - val_loss: 2.0427 - val_accuracy: 0.4974\n",
      "number of unlabeled samples remained: 1688\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 1.5296 - accuracy: 0.7376 - val_loss: 2.0222 - val_accuracy: 0.5095\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 1.6204 - accuracy: 0.6525 - val_loss: 2.0031 - val_accuracy: 0.5129\n",
      "number of unlabeled samples remained: 1268\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.5264 - accuracy: 0.7092 - val_loss: 1.9838 - val_accuracy: 0.5181\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.5148 - accuracy: 0.7518 - val_loss: 1.9641 - val_accuracy: 0.5215\n",
      "number of unlabeled samples remained: 848\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 1.4892 - accuracy: 0.7092 - val_loss: 1.9469 - val_accuracy: 0.5267\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.4588 - accuracy: 0.7092 - val_loss: 1.9296 - val_accuracy: 0.5267\n",
      "number of unlabeled samples remained: 428\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 1.4375 - accuracy: 0.7163 - val_loss: 1.9126 - val_accuracy: 0.5353\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.4053 - accuracy: 0.7376 - val_loss: 1.8950 - val_accuracy: 0.5370\n",
      "number of unlabeled samples remained: 8\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 1.3617 - accuracy: 0.7872 - val_loss: 1.8786 - val_accuracy: 0.5404\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.4210 - accuracy: 0.7163 - val_loss: 1.8625 - val_accuracy: 0.5439\n",
      "number of unlabeled samples remained: 0\n",
      "fine tuning the model (iteration 1)\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.3904 - accuracy: 0.7447 - val_loss: 1.8458 - val_accuracy: 0.5422\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.3650 - accuracy: 0.7305 - val_loss: 1.8308 - val_accuracy: 0.5456\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.3591 - accuracy: 0.7872 - val_loss: 1.8154 - val_accuracy: 0.5542\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.3231 - accuracy: 0.7518 - val_loss: 1.8016 - val_accuracy: 0.5577\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.2851 - accuracy: 0.7660 - val_loss: 1.7883 - val_accuracy: 0.5611\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.2632 - accuracy: 0.7660 - val_loss: 1.7755 - val_accuracy: 0.5645\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.2478 - accuracy: 0.7801 - val_loss: 1.7607 - val_accuracy: 0.5697\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.2884 - accuracy: 0.7730 - val_loss: 1.7470 - val_accuracy: 0.5749\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.2203 - accuracy: 0.7801 - val_loss: 1.7340 - val_accuracy: 0.5749\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.2297 - accuracy: 0.7872 - val_loss: 1.7227 - val_accuracy: 0.5749\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.1728 - accuracy: 0.8511 - val_loss: 1.7107 - val_accuracy: 0.5800\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0801 - accuracy: 0.8227 - val_loss: 1.6986 - val_accuracy: 0.5886\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.1736 - accuracy: 0.7943 - val_loss: 1.6851 - val_accuracy: 0.5955\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.1099 - accuracy: 0.8511 - val_loss: 1.6737 - val_accuracy: 0.6059\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0707 - accuracy: 0.8227 - val_loss: 1.6625 - val_accuracy: 0.6093\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0839 - accuracy: 0.7943 - val_loss: 1.6520 - val_accuracy: 0.6110\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0611 - accuracy: 0.8014 - val_loss: 1.6402 - val_accuracy: 0.6127\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.1047 - accuracy: 0.8511 - val_loss: 1.6290 - val_accuracy: 0.6145\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0758 - accuracy: 0.7943 - val_loss: 1.6177 - val_accuracy: 0.6162\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0326 - accuracy: 0.8085 - val_loss: 1.6089 - val_accuracy: 0.6179\n"
     ]
    }
   ],
   "source": [
    "model_list = [None] * 1\n",
    "    \n",
    "# the main training loop\n",
    "for i in range(1):\n",
    "  \n",
    "    model = model\n",
    "    train_ds, val_ds = shuffle_train_val()\n",
    "    samps = samples\n",
    "    unlabeled = unlabeled_samps\n",
    "\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    unlabeled_batch = int(0.1 * unlabeled_len)\n",
    "    \n",
    "    # finish training this iteration until all unlabeled data are used\n",
    "    while len(unlabeled) > 0:\n",
    "        hist = model.fit(train_ds, validation_data=val_ds, epochs=2, shuffle=True)\n",
    "        improvement = hist.history['val_accuracy'][-1] - hist.history['val_accuracy'][-2]\n",
    "            \n",
    "        # as long as the model stop moving forward, start training unlabeled samples\n",
    "        if improvement <= 0.01:\n",
    "            preds = Add_labels(unlabeled, model, min(len(unlabeled), unlabeled_batch))\n",
    "            pred_ds = tf.data.Dataset.from_tensor_slices((preds[:,0], preds[:,1]))\n",
    "            pred_ds = pred_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "            pred_ds = configure_for_performance(pred_ds)\n",
    "      \n",
    "            # keep updating the training set and the unlabeled set\n",
    "            train_ds.concatenate(pred_ds)\n",
    "            unlabeled = [j for j in unlabeled if j not in preds[:,0]]\n",
    "            print(f\"number of unlabeled samples remained: {len(unlabeled)}\")\n",
    "           \n",
    "    # train all labeled and unlabeled data\n",
    "    print(f\"fine tuning the model (iteration {i+1})\")\n",
    "    model.fit(train_ds,validation_data=val_ds,epochs=20,shuffle=True)\n",
    "        \n",
    "    # keep track of the trained models\n",
    "    model_list[i] = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYZusKag9aVk",
    "outputId": "45c78a15-6a67-46ee-a9db-0ceecc8d71db",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 1.0251 - accuracy: 0.8227 - val_loss: 1.5999 - val_accuracy: 0.6196\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.0501 - accuracy: 0.8227 - val_loss: 1.5904 - val_accuracy: 0.6213\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 1.0547 - accuracy: 0.7801 - val_loss: 1.5815 - val_accuracy: 0.6248\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.9799 - accuracy: 0.8227 - val_loss: 1.5727 - val_accuracy: 0.6265\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0387 - accuracy: 0.8298 - val_loss: 1.5627 - val_accuracy: 0.6282\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.9999 - accuracy: 0.8156 - val_loss: 1.5535 - val_accuracy: 0.6299\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.9475 - accuracy: 0.8511 - val_loss: 1.5449 - val_accuracy: 0.6334\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.9318 - accuracy: 0.8582 - val_loss: 1.5358 - val_accuracy: 0.6334\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.9426 - accuracy: 0.8369 - val_loss: 1.5275 - val_accuracy: 0.6351\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.9532 - accuracy: 0.8440 - val_loss: 1.5196 - val_accuracy: 0.6351\n"
     ]
    }
   ],
   "source": [
    "hist7 = model_list[-1].fit(train_ds,validation_data=val_ds,epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLSzNUOw9aVl"
   },
   "outputs": [],
   "source": [
    "np.save('hist7.npy',hist7.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ssI0Hf99aVl"
   },
   "outputs": [],
   "source": [
    "hist = np.load('hist1.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_4nTQoa9aVl"
   },
   "outputs": [],
   "source": [
    "hist2 = np.load('hist2.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpPs4SWetAo4"
   },
   "source": [
    "# Output submission csv for Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7whMUop9aVl"
   },
   "outputs": [],
   "source": [
    "test_ds = test_ds.batch(1)\n",
    "\n",
    "with open('submission_task2_semisupervised.csv', 'w') as f:\n",
    "  f.write('id,predicted\\n')\n",
    "  for image_batch, image_names in test_ds:\n",
    "    predictions = model_list[-1].predict(image_batch)\n",
    "    for image_name, predictions in zip(image_names.numpy(), model.predict(image_batch)):\n",
    "      inds = np.argmax(predictions)\n",
    "      line = str(int(image_name)) + ',' + class_names[inds]\n",
    "      f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt7OaOehvoh1"
   },
   "source": [
    "**Note**\n",
    "\n",
    "Absolute path is recommended here. For example, use \"/projectnb2/cs542-bap/[your directory name]/submission_task2_supervised.csv\" to replace \"submission_task2_supervised.csv\".\n",
    "\n",
    "Besides, you can request good resources by specify the type of gpus, such as \"qsub -l gpus=1 -l gpu_type=P100 [your file name].qsub\". This is helpful to avoid potential issues of GPUs, such as out of memory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVPDt6i-9aVm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sren_t2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
